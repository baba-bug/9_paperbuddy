import os
import time
import wave
import struct
import collections
import contextlib
import threading
import datetime
import sys
import shutil

# Check for required packages
try:
    import pyautogui
    import pyaudio
    import webrtcvad
    import numpy as np
    import google.generativeai as genai
    from PIL import Image
except ImportError as e:
    print(f"âŒ Missing dependency: {e}")
    print("Please run: pip install -r requirements.txt")
    sys.exit(1)

# ================= é…ç½®åŒºåŸŸ =================
# Try to get API key from environment variable, otherwise use the placeholder
API_KEY = 'AIzaSyC6nkwM8qSlIR1PJhho1LLFrStTCCDGJ1A'
MODEL_NAME = 'gemini-2.5-flash'

# Paths relative to src/
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(os.path.dirname(BASE_DIR), 'data')
OUTPUT_FILE = os.path.join(DATA_DIR, "Research_Log.md")
RECORDINGS_DIR = os.path.join(DATA_DIR, "recordings")
SCREENSHOTS_DIR = os.path.join(DATA_DIR, "screenshots")

# Ensure directories exist
os.makedirs(RECORDINGS_DIR, exist_ok=True)
os.makedirs(SCREENSHOTS_DIR, exist_ok=True)

# Audio Configuration
RATE = 16000 
CHANNELS = 1
FORMAT = pyaudio.paInt16
FRAME_DURATION_MS = 30
PADDING_DURATION_MS = 1500
CHUNK_SIZE = int(RATE * FRAME_DURATION_MS / 1000)

# ================= åˆå§‹åŒ– =================
if "åœ¨è¿™é‡Œå¡«å…¥ä½ çš„" in API_KEY:
    print("âš ï¸  WARNING: API Key not set. Please set GOOGLE_API_KEY env var or edit the script.")

try:
    genai.configure(api_key=API_KEY)
    model = genai.GenerativeModel(MODEL_NAME)
except Exception as e:
    print(f"âŒ Failed to configure Gemini API: {e}")

vad = webrtcvad.Vad(3)

def check_ffmpeg():
    """Check if FFmpeg is installed and in PATH."""
    if not shutil.which("ffmpeg"):
        print("âŒ FFmpeg not found! Please install FFmpeg and add it to your PATH.")
        print("Download: https://gyan.dev/ffmpeg/builds/")
        return False
    return True

class AudioRecorder:
    def __init__(self):
        self.p = pyaudio.PyAudio()
        try:
            self.stream = self.p.open(format=FORMAT,
                                      channels=CHANNELS,
                                      rate=RATE,
                                      input=True,
                                      frames_per_buffer=CHUNK_SIZE)
        except OSError as e:
            print(f"âŒ Failed to open audio stream: {e}")
            print("Please ensure a microphone is connected and accessible.")
            self.stream = None
        
        self.history = collections.deque(maxlen=int(PADDING_DURATION_MS / FRAME_DURATION_MS))
        
    def read(self):
        if self.stream:
            try:
                data = self.stream.read(CHUNK_SIZE, exception_on_overflow=False)
                return data
            except Exception as e:
                print(f"Audio read error: {e}")
                return b'\x00' * CHUNK_SIZE
        return b'\x00' * CHUNK_SIZE # Return silence if no stream

    def close(self):
        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
        self.p.terminate()

def save_wav(frames, filename):
    try:
        wf = wave.open(filename, 'wb')
        wf.setnchannels(CHANNELS)
        wf.setsampwidth(2) # 16-bit
        wf.setframerate(RATE)
        wf.writeframes(b''.join(frames))
        wf.close()
    except Exception as e:
        print(f"âŒ Error saving WAV: {e}")

def analyze_content(audio_path, screenshot_path):
    """Send to Gemini for multimodal analysis."""
    print(" -> æ­£åœ¨ä¸Šä¼ å¹¶åˆ†æ...")
    try:
        # Check if files exist
        if not os.path.exists(audio_path):
            print(f"âŒ Audio file not found: {audio_path}")
            return
        if not os.path.exists(screenshot_path):
            print(f"âŒ Screenshot file not found: {screenshot_path}")
            return

        # Upload audio
        audio_file = genai.upload_file(path=audio_path)
        
        # Open image
        img = Image.open(screenshot_path)
        
        prompt = """
        åœºæ™¯ï¼šæˆ‘æ­£åœ¨ç”µè„‘ä¸Šçœ‹è®ºæ–‡/å†™ä»£ç ï¼Œè¿™æ˜¯æˆ‘çš„å±å¹•æˆªå›¾ï¼Œé™„ä»¶æ˜¯æˆ‘åˆšæ‰è¯´çš„è¯ã€‚
        ä»»åŠ¡ï¼šè¯·ç»“åˆå±å¹•å†…å®¹ï¼ŒæŠŠæˆ‘çš„å£è¯­ï¼ˆå¯èƒ½åŒ…å«åæ§½ã€ç–‘é—®ã€æ€è·¯ï¼‰è½¬åŒ–ä¸ºè¿™ç¯‡è®ºæ–‡çš„ç»“æ„åŒ–ç¬”è®°ã€‚
        è¦æ±‚ï¼š
        1. **é€å­—ç¨¿**ï¼šé¦–å…ˆä½ éœ€è¦å°½å¯èƒ½å‡†ç¡®åœ°è½¬å½•æˆ‘è¯´çš„è¯ï¼ˆVerbatim Transcriptï¼‰ã€‚
        2. **åˆ†æ**ï¼šå¦‚æœæˆ‘åœ¨è¯»ç‰¹å®šæ®µè½ï¼Œè¯·ç»“åˆæˆªå›¾æŒ‡å‡ºæˆ‘å…³æ³¨çš„å†…å®¹ã€‚
        3. ç”¨ä¸­æ–‡å›ç­”ï¼Œæ ¼å¼ç®€æ´ï¼Œä½¿ç”¨Markdownç»“æ„ã€‚
        
        è¾“å‡ºæ ¼å¼å¦‚ä¸‹ï¼š
        ## ğŸ—£ï¸ å£è¯­é€å­—ç¨¿
        (ä½ çš„è½¬å½•å†…å®¹)
        
        ## ğŸ“ ç»“æ„åŒ–ç¬”è®°
        (ä½ çš„åˆ†æå†…å®¹)
        """
        
        response = model.generate_content([prompt, img, audio_file])
        
        # Write to file
        timestamp = datetime.datetime.now().strftime("%H:%M:%S")
        note_content = f"\n> **[{timestamp}]**\n{response.text}\n---\n"
        
        with open(OUTPUT_FILE, "a", encoding="utf-8") as f:
            f.write(note_content)
            
        print(f"âœ… ç¬”è®°å·²æ›´æ–°: {OUTPUT_FILE}")
        
        # Cleanup - Delete from cloud but KEEP local files for records
        try:
            audio_file.delete()
        except:
            pass
        
    except Exception as e:
        print(f"âŒ åˆ†æå‡ºé”™: {e}")

def main():
    print(f"ğŸš€ AI è®ºæ–‡ä¼´ä¾£å·²å¯åŠ¨ (Windows/RTX4060ç‰ˆ)")
    
    if not check_ffmpeg():
        return

    print(f"ğŸ“ ç¬”è®°å°†ä¿å­˜è‡³: {os.path.abspath(OUTPUT_FILE)}")
    print(f"ğŸ“‚ å½•éŸ³å°†ä¿å­˜è‡³: {os.path.abspath(RECORDINGS_DIR)}")
    print("ğŸ™ï¸  è¯·å¼€å§‹çœ‹è®ºæ–‡å¹¶è¯´è¯ (æ£€æµ‹åˆ°é™éŸ³ä¼šè‡ªåŠ¨æäº¤)... æŒ‰ Ctrl+C é€€å‡º")

    recorder = AudioRecorder()
    if not recorder.stream:
        print("âŒ Microphone not initialized.")
        return

    # State variables
    triggered = False
    voiced_frames = []
    ring_buffer = collections.deque(maxlen=20) 
    
    try:
        while True:
            chunk = recorder.read()
            try:
                is_speech = vad.is_speech(chunk, RATE)
            except Exception:
                # If chunk is partial or invalid, assume silence
                is_speech = False
            
            if not triggered:
                ring_buffer.append(chunk)
                if is_speech:
                    print("ğŸ”´ æ£€æµ‹åˆ°è¯­éŸ³ï¼Œå¼€å§‹å½•åˆ¶...")
                    triggered = True
                    voiced_frames.extend(ring_buffer)
                    voiced_frames.append(chunk)
            else:
                voiced_frames.append(chunk)
                if is_speech:
                    recorder.history.clear()
                else:
                    recorder.history.append(chunk)
                    if len(recorder.history) == recorder.history.maxlen:
                        print("â¹ï¸  è¯´è¯ç»“æŸï¼Œå¼€å§‹å¤„ç†...")
                        triggered = False
                        
                        # 1. Generate unique filenames
                        timestamp_str = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")
                        audio_filename = os.path.join(RECORDINGS_DIR, f"capture_{timestamp_str}.wav")
                        screenshot_filename = os.path.join(SCREENSHOTS_DIR, f"capture_{timestamp_str}.png")
                        
                        save_wav(voiced_frames, audio_filename)
                        
                        # 2. Screenshot
                        pyautogui.screenshot(screenshot_filename)
                        
                        # 3. Asynchronous processing
                        analysis_thread = threading.Thread(target=analyze_content, args=(audio_filename, screenshot_filename))
                        analysis_thread.start()
                        
                        # Reset for next sentence
                        voiced_frames = []
                        ring_buffer.clear()
                        recorder.history.clear()
                        print("ğŸ™ï¸  ç»§ç»­ç›‘å¬ä¸­...")

    except KeyboardInterrupt:
        print("\nğŸ‘‹ é€€å‡ºç¨‹åº")
        recorder.close()

if __name__ == "__main__":
    main()

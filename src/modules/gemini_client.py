import google.generativeai as genai
from PIL import Image
import os
import time
import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from .utils import API_KEY, MODEL_NAME


def configure_genai():
    if not API_KEY:
        print("âš ï¸  WARNING: API Key not set. Please create a .env file.")
        return None
    try:
        genai.configure(api_key=API_KEY)
        return genai.GenerativeModel(MODEL_NAME)
    except Exception as e:
        print(f"âŒ Failed to configure Gemini API: {e}")
        return None


# Global model instance
model = configure_genai()


def batch_analyze(file_list, output_file, archive_dir=None):
    """
    Upload a batch of files (images, audio, video) to Gemini and get a summary.
    
    Args:
        file_list: List of absolute file paths, sorted by timestamp.
        output_file: Path to Research_Log.md to append results.
        archive_dir: Path to archive directory (for embedding file links in log).
    """
    if not model:
        print("âŒ Model not configured. Check your .env file.")
        return False

    if not file_list:
        print("  (no files to analyze)")
        return True

    print(f"  ğŸ“¤ Uploading {len(file_list)} files to Gemini (parallel)...")
    uploaded_files = []
    content_parts = []

    try:
        # Upload all files in parallel
        def _upload_one(fpath):
            uploaded = genai.upload_file(path=fpath)
            print(f"    âœ… {os.path.basename(fpath)}")
            return uploaded

        with ThreadPoolExecutor(max_workers=8) as executor:
            futures = {executor.submit(_upload_one, fp): fp for fp in file_list}
            for future in as_completed(futures):
                fpath = futures[future]
                try:
                    uploaded_files.append(future.result())
                except Exception as e:
                    print(f"    âŒ Failed to upload {os.path.basename(fpath)}: {e}")

        if not uploaded_files:
            print("  âŒ No files were uploaded successfully.")
            return False

        # Wait for files to become ACTIVE
        print("  â³ Waiting for files to be processed...")
        for uf in uploaded_files:
            _wait_for_active(uf)

        # Build prompt
        prompt = """
ä½ æ˜¯ä¸€ä¸ªAIç ”ç©¶åŠ©æ‰‹ã€‚ä»¥ä¸‹æ˜¯ç”¨æˆ·è¿‡å»ä¸€æ®µæ—¶é—´çš„å·¥ä½œæµè®°å½•ã€‚

æ•°æ®åŒ…å«ï¼š
- **è¯­éŸ³ç‰‡æ®µ** (.wav)ï¼šç”¨æˆ·åœ¨çœ‹è®ºæ–‡/å†™ä»£ç æ—¶è¯´çš„è¯ï¼ˆå¯èƒ½åŒ…å«åæ§½ã€ç–‘é—®ã€æ€è·¯ï¼‰
- **å±å¹•å½•åƒ** (.mp4)ï¼šä¸è¯­éŸ³åŒæ­¥çš„å±å¹•å½•åˆ¶
- **å®šæ—¶æˆªå›¾** (.jpg)ï¼šæ¯10ç§’è‡ªåŠ¨æˆªå–çš„å±å¹•ç”»é¢

è¯·æŒ‰ç…§æ—¶é—´é¡ºåºï¼Œå®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š
1. **é€å­—è½¬å½•**ï¼šå°†æ¯æ®µè¯­éŸ³å°½å¯èƒ½å‡†ç¡®åœ°è½¬å½•ä¸ºæ–‡å­—ã€‚
2. **æ“ä½œè·¯å¾„è¿˜åŸ**ï¼šæ ¹æ®æˆªå›¾å’Œè§†é¢‘ï¼Œç®€æ´åœ°è¿˜åŸç”¨æˆ·çš„æ“ä½œè·¯å¾„ï¼ˆçœ‹äº†ä»€ä¹ˆã€åšäº†ä»€ä¹ˆï¼‰ï¼Œæ¯ä¸€ä¸ªæ“ä½œç”¨ä¸€å¥è¯æ¦‚æ‹¬ã€‚
3. **ç»“æ„åŒ–æ€»ç»“**ï¼šç”ŸæˆMarkdownæ ¼å¼çš„æ€»ç»“ã€‚

è¾“å‡ºæ ¼å¼ï¼š
## ğŸ“‹ æ—¶é—´æ®µæ€»ç»“ [HH:MM - HH:MM]

### ğŸ—£ï¸ è¯­éŸ³è½¬å½•
(æŒ‰æ—¶é—´é¡ºåºåˆ—å‡ºæ¯æ®µè¯­éŸ³çš„è½¬å½•)

### ğŸ–¥ï¸ æ“ä½œè·¯å¾„
(å¯¹ä»–è¿™æ®µæ—¶é—´çš„æ“ä½œè¿›è¡Œé«˜å±‚çš„è¯­ä¹‰ç†è§£)
"""
        content_parts.append(prompt)
        content_parts.extend(uploaded_files)

        print("  ğŸ§  Analyzing with Gemini...")
        response = model.generate_content(content_parts)

        # Build file reference section
        file_refs = _build_file_references(file_list, output_file, archive_dir)

        # Write to log
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        note_content = f"\n---\n\n> **[Batch Analysis: {timestamp}]**\n\n{response.text}\n\n{file_refs}\n\n---\n"

        with open(output_file, "a", encoding="utf-8") as f:
            f.write(note_content)

        print(f"  âœ… åˆ†æå®Œæˆ, å†™å…¥: {os.path.basename(output_file)}")

        # Cleanup cloud uploads
        for uf in uploaded_files:
            try:
                uf.delete()
            except:
                pass

        return True

    except Exception as e:
        print(f"  âŒ Batch analysis error: {e}")
        return False


def _build_file_references(file_list, output_file, archive_dir):
    """Build markdown section with links to archived media files."""
    if not archive_dir:
        return ""

    # Calculate relative path from Research_Log.md to archive/
    log_dir = os.path.dirname(output_file)
    rel_archive = os.path.relpath(archive_dir, log_dir)

    screenshots = []
    audio_clips = []
    video_clips = []

    for fpath in file_list:
        fname = os.path.basename(fpath)
        rel_path = f"{rel_archive}/{fname}"
        if fname.endswith(".jpg"):
            screenshots.append(f"![{fname}]({rel_path})")
        elif fname.endswith(".wav"):
            audio_clips.append(f"- ğŸ™ï¸ [{fname}]({rel_path})")
        elif fname.endswith(".mp4"):
            video_clips.append(f"- ğŸ¬ [{fname}]({rel_path})")

    parts = ["<details>\n<summary>ğŸ“ æœ¬æ¬¡åˆ†æçš„åŸå§‹ç´ æ</summary>\n"]

    if screenshots:
        parts.append("**æˆªå›¾:**")
        for s in screenshots:
            parts.append(s)
        parts.append("")

    if audio_clips:
        parts.append("**è¯­éŸ³:**")
        parts.extend(audio_clips)
        parts.append("")

    if video_clips:
        parts.append("**å½•å±:**")
        parts.extend(video_clips)
        parts.append("")

    parts.append("</details>")
    return "\n".join(parts)


def _wait_for_active(uploaded_file, timeout=120):
    """Wait for an uploaded file to become ACTIVE (ready for use)."""
    start = time.time()
    while time.time() - start < timeout:
        try:
            f = genai.get_file(uploaded_file.name)
            if f.state.name == "ACTIVE":
                return True
        except:
            pass
        time.sleep(2)
    print(f"  âš ï¸ File {uploaded_file.name} did not become ACTIVE in time.")
    return False

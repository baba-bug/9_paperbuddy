import google.generativeai as genai
from PIL import Image
import os
import datetime
from .utils import API_KEY, MODEL_NAME, OUTPUT_FILE

def configure_genai():
    if "åœ¨è¿™é‡Œå¡«å…¥ä½ çš„" in API_KEY:
        print("âš ï¸  WARNING: API Key not set.")
    try:
        genai.configure(api_key=API_KEY)
        return genai.GenerativeModel(MODEL_NAME)
    except Exception as e:
        print(f"âŒ Failed to configure Gemini API: {e}")
        return None

# Global model instance
model = configure_genai()

def analyze_content(audio_path, screenshot_path):
    """Send to Gemini for multimodal analysis."""
    print(" -> æ­£åœ¨ä¸Šä¼ å¹¶åˆ†æ...")
    if not model:
        print("âŒ Model not configured.")
        return

    try:
        # Check if files exist
        if not os.path.exists(audio_path):
            print(f"âŒ Audio file not found: {audio_path}")
            return
        if not os.path.exists(screenshot_path):
            print(f"âŒ Screenshot file not found: {screenshot_path}")
            return

        # Upload audio
        audio_file = genai.upload_file(path=audio_path)
        
        # Open image
        img = Image.open(screenshot_path)
        
        prompt = """
        åœºæ™¯ï¼šæˆ‘æ­£åœ¨ç”µè„‘ä¸Šçœ‹è®ºæ–‡/å†™ä»£ç ï¼Œè¿™æ˜¯æˆ‘çš„å±å¹•æˆªå›¾ï¼Œé™„ä»¶æ˜¯æˆ‘åˆšæ‰è¯´çš„è¯ã€‚
        ä»»åŠ¡ï¼šè¯·ç»“åˆå±å¹•å†…å®¹ï¼ŒæŠŠæˆ‘çš„å£è¯­ï¼ˆå¯èƒ½åŒ…å«åæ§½ã€ç–‘é—®ã€æ€è·¯ï¼‰è½¬åŒ–ä¸ºè¿™ç¯‡è®ºæ–‡çš„ç»“æ„åŒ–ç¬”è®°ã€‚
        è¦æ±‚ï¼š
        1. **é€å­—ç¨¿**ï¼šé¦–å…ˆä½ éœ€è¦å°½å¯èƒ½å‡†ç¡®åœ°è½¬å½•æˆ‘è¯´çš„è¯ï¼ˆVerbatim Transcriptï¼‰ã€‚
        2. **åˆ†æ**ï¼šå¦‚æœæˆ‘åœ¨è¯»ç‰¹å®šæ®µè½ï¼Œè¯·ç»“åˆæˆªå›¾æŒ‡å‡ºæˆ‘å…³æ³¨çš„å†…å®¹ã€‚
        3. ç”¨ä¸­æ–‡å›ç­”ï¼Œæ ¼å¼ç®€æ´ï¼Œä½¿ç”¨Markdownç»“æ„ã€‚
        
        è¾“å‡ºæ ¼å¼å¦‚ä¸‹ï¼š
        ## ğŸ—£ï¸ å£è¯­é€å­—ç¨¿
        (ä½ çš„è½¬å½•å†…å®¹)
        
        ## ğŸ“ ç»“æ„åŒ–ç¬”è®°
        (ä½ çš„åˆ†æå†…å®¹)
        """
        
        response = model.generate_content([prompt, img, audio_file])
        
        # Write to file
        timestamp = datetime.datetime.now().strftime("%H:%M:%S")
        
        # Create relative path for the image in the markdown
        # valid markdown path from data/Research_Log.md to data/screenshots/image.png is just screenshots/image.png
        # We need to extract the filename from screenshot_path
        filename = os.path.basename(screenshot_path)
        relative_img_path = f"screenshots/{filename}"

        note_content = f"""
> **[{timestamp}]**
{response.text}

<details>
<summary>ğŸ“¸ ç‚¹å‡»æŸ¥çœ‹å±å¹•æˆªå›¾</summary>
<img src="{relative_img_path}" width="800" />
</details>

---
"""
        
        with open(OUTPUT_FILE, "a", encoding="utf-8") as f:
            f.write(note_content)
            
        print(f"âœ… ç¬”è®°å·²æ›´æ–°: {OUTPUT_FILE}")
        
        # Cleanup
        try:
            audio_file.delete()
        except:
            pass
        
    except Exception as e:
        print(f"âŒ åˆ†æå‡ºé”™: {e}")
